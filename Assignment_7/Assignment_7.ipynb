{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Assignment_7.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEfTKFQJyosU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "dff70101-db6d-47af-bef4-01e45d3df437"
      },
      "source": [
        "#Imoporing required packages\n",
        "import tensorflow as tf\n",
        "import keras\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UzGd3vLsEiG1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "20b3bc0f-9fe3-4bea-a822-6cc0bbfbaa48"
      },
      "source": [
        "#Mounting Google Drive to colab\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgRgvOjJGPYb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#Importing data from google drive\n",
        "filename = \"/content/gdrive/My Drive/shakespeare_input.txt\"\n",
        "raw_text = open(filename).read()\n",
        "raw_text = raw_text.lower()\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FW9JO8a_L6mS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "#create mapping of unique characters to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-i6S_NqaMPy5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "outputId": "c888b0b2-4394-4ea1-cd31-b1482a65dd16"
      },
      "source": [
        "#Vocabs and Characters\n",
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocabs: \", n_vocab)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  4573338\n",
            "Total Vocabs:  41\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ghzIkNQoMpc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b78683fa-12fb-463c-9308-34d0d8e40d1d"
      },
      "source": [
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  4573238\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-y_AV6dkTuOB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NSOQRlfE281j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# normalize\n",
        "X = X / float(n_vocab)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ORaNLmsVF-Q",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RFCJFBHaUk7f",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mpnhr0g6VkE5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qpFpNQiUMY_H",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#1-layer LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnLuGGA4Uw4Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2-layer LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]),return_sequences=True))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(LSTM(256))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cdR7Z-jxVcAi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iZ6jzVtLVsiV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 245
        },
        "outputId": "8487cd92-bd75-444e-fb6c-f5fb2996a8b1"
      },
      "source": [
        "model.fit(X, y, epochs=2, batch_size=1024, callbacks=callbacks_list)"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "W0701 09:31:46.707587 140440527189888 deprecation.py:323] From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/2\n",
            "4573238/4573238 [==============================] - 1812s 396us/step - loss: 2.4363\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.43631, saving model to weights-improvement-01-2.4363.hdf5\n",
            "Epoch 2/2\n",
            "4573238/4573238 [==============================] - 1805s 395us/step - loss: 2.0094\n",
            "\n",
            "Epoch 00002: loss improved from 2.43631 to 2.00943, saving model to weights-improvement-02-2.0094.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fba7d586b00>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wD9Kz_PVwJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load the network weights (#one layer LSTM checkpoint)\n",
        "filename = \"weights-improvement-01-2.5026.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vfTzx_V-c7Pi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5XJbI5Lgc-Gu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 746
        },
        "outputId": "7d77e142-c3fc-478a-8c40-f729c2e43d46"
      },
      "source": [
        "#Text generation after training the LSTM \n",
        "import sys\n",
        "# pick a random seed\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" eems warm upon her lip.\n",
            "\n",
            "leontes:\n",
            "the fixture of her eye has motion in't,\n",
            "as we are mock'd with art. \"\n",
            "n toee to toee toe\n",
            "tore the world tfat the world that soeek to meve\n",
            "the world of the sore tf tee the ponee tfat the sore\n",
            "\n",
            "she sooe th tee the pone of the sore tf teee to toee toeee \n",
            "she sooe the world tfat the pooe of the sore\n",
            "\n",
            "soe toank the pone tf tee the pone of the sore\n",
            "\n",
            "soe toank the tore tf tee the pone of the sore\n",
            "\n",
            "soe toanke to the pone of the sore tfat toen the sore\n",
            "\n",
            "soe toanker \n",
            "iore to the pone oo the pante \n",
            "for the world to the world to toee to meve\n",
            "the world of the sore tf tee the ponee tfat toe\n",
            "toane to the world tfat the world that toen the sore\n",
            "\n",
            "soe toanker \n",
            "io the sore tf tee the pone of the sore\n",
            "\n",
            "soe toankee ie the world of the sore \n",
            "she sooe the sooe tf tee to toee the sore\n",
            "\n",
            "soe toank the tore tf tee the pone of the sore to tee toeee\n",
            "the tore tf tee the pone of the sore tfat toene\n",
            "to the tore tf tee the pone of the sore\n",
            "\n",
            "soe dnnreet oo the sore tf tee the pone\n",
            "to the tore tf tee the tore\n",
            "tfet saal the pone of the sore\n",
            "\n",
            "soe dnnreeti oo the sore to the pone tfat toene\n",
            "\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KtY3BPsadDbK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#2-layer LSTM \n",
        "# load the network weights\n",
        "filename = \"weights-improvement-02-2.0094.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qTQuFR5EGggR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iIkRWlizGqMV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 159
        },
        "outputId": "7439d12a-3ed9-4262-ea9e-c29d0fbe76cd"
      },
      "source": [
        "#Text generation after training the LSTM \n",
        "import sys\n",
        "# pick a random seed\n",
        "start = np.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = np.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = np.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" re virtuous:\n",
            "nor from mine own weak merits will i draw\n",
            "the smallest fear or doubt of her revolt;\n",
            "for \"\n",
            " the counter of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears of the sears\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqRoPHpxGuny",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "##Conclusion: Build and trained two LSTM model i.e 1 layer and 2 layer model with dropout.\n",
        "##2-layer LSTM is overfitting where as 1 layer model did not overfit.\n",
        "##1 layer model performed better than 2 layer model.\n",
        "##Only two epochs and 1024 batch size is used for faster training as it takes really long time for larger epochs and lesser batch size.\n",
        "  "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1AHNPTVzI19g",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
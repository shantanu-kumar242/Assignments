{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "597wDiAvGvuB"
   },
   "outputs": [],
   "source": [
    "#Importing Required packages\n",
    "import numpy as np\n",
    "import idx2numpy\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#MNIST contains images of hand-written digits, each 28 x 28 pixels, in greyscale with pixel-values from 0 to 255.\n",
    "file = 'train-images-idx3-ubyte'   #importing training images\n",
    "arr = idx2numpy.convert_from_file(file)   #converting to numpy array\n",
    "file1 = 'train-labels-idx1-ubyte'       #importing training labels\n",
    "arr1 = idx2numpy.convert_from_file(file1)  #converting to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = arr\n",
    "x_train = x_train.flatten().reshape(-1,28*28) #Flatten to give input in input node\n",
    "x_train = x_train / 255.0    #Weâ€™ll normalize the data to keep our gradients manageable\n",
    "gt_indices = arr1\n",
    "train_length = len(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64 #batch size was tuned by using 32/64\n",
    "input_dim = 784 #number of nodes in input nodes is 28*28\n",
    "hidden_1_dim = 512  #Number of nodes in first hidden layer was tuned by taking 256/392/512\n",
    "output_dim = 10   # For 10 digits, output layers has 10 nodes \n",
    "learning_rate = 1e-2  #Learning rate is tuned by taking 1e-1/1e-2/1e-3/1e-4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hImaaujc5zXg"
   },
   "outputs": [],
   "source": [
    "y_train = np.zeros((train_length, output_dim))\n",
    "for i in range(train_length):\n",
    "    y_train[i,gt_indices[i]] = 1\n",
    "\n",
    "num_minibatches = np.floor(train_length/batch_size).astype(int) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "C9HRf0Wj52cK"
   },
   "outputs": [],
   "source": [
    "W1 = 0.2*np.random.randn(input_dim, hidden_1_dim) #Random Weight Initialisation for nodes between input and first hidden layer\n",
    "W2 = 0.2*np.random.randn(hidden_1_dim,output_dim)   #Random weight initialisation for nodes between first hidden layer and output layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu(a):                    #Relu Activation Function to be used in hidden layer\n",
    "    return np.maximum(a,0)\n",
    "\n",
    "def grad_relu(x):               #Gradient of Relu Activation Function\n",
    "    return 1. * (x > 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "PmZRrEVb6CJy"
   },
   "outputs": [],
   "source": [
    "def softmax(z):                    #Softmax activation function, to be used at outer layer\n",
    "  \n",
    "    return np.exp(z) / np.sum(np.exp(z),axis=1,keepdims=True)\n",
    "    \n",
    "    pass\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 697
    },
    "colab_type": "code",
    "id": "Gjz4yhwE6JQw",
    "outputId": "341578db-29a4-48ca-b0f8-a0343aadd24b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Epoch: 0, iteration: 0, Loss: 9.3504 \n",
      " Epoch: 1, iteration: 937, Loss: 0.1230 \n",
      " Epoch: 2, iteration: 1874, Loss: 0.0881 \n",
      " Epoch: 3, iteration: 2811, Loss: 0.0175 \n",
      " Epoch: 4, iteration: 3748, Loss: 0.0121 \n",
      " Epoch: 5, iteration: 4685, Loss: 0.0094 \n",
      " Epoch: 6, iteration: 5622, Loss: 0.0069 \n",
      " Epoch: 7, iteration: 6559, Loss: 0.0032 \n",
      " Epoch: 8, iteration: 7496, Loss: 0.0023 \n",
      " Epoch: 9, iteration: 8433, Loss: 0.0021 \n",
      " Epoch: 10, iteration: 9370, Loss: 0.0035 \n",
      " Epoch: 11, iteration: 10307, Loss: 0.0033 \n",
      " Epoch: 12, iteration: 11244, Loss: 0.0031 \n",
      " Epoch: 13, iteration: 12181, Loss: 0.0029 \n",
      " Epoch: 14, iteration: 13118, Loss: 0.0028 \n",
      " Epoch: 15, iteration: 14055, Loss: 0.0027 \n",
      " Epoch: 16, iteration: 14992, Loss: 0.0026 \n",
      " Epoch: 17, iteration: 15929, Loss: 0.0025 \n",
      " Epoch: 18, iteration: 16866, Loss: 0.0024 \n",
      " Epoch: 19, iteration: 17803, Loss: 0.0023 \n",
      " Epoch: 20, iteration: 18740, Loss: 0.0022 \n",
      " Epoch: 21, iteration: 19677, Loss: 0.0022 \n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "no_of_iterations = 20000          # Number of iterations was tuned by using 10000/15000/20000/25000/30000\n",
    "loss_list=[]\n",
    "i = []\n",
    "i_epoch = 0\n",
    "\n",
    "for i_iter in range(no_of_iterations):\n",
    "    #Forward Propagation\n",
    "    batch_elem_idx = i_iter%num_minibatches\n",
    "    x_batchinput = x_train[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size]\n",
    "    a1 =x_batchinput@W1\n",
    "    h1 =relu(a1)\n",
    "    a2 = h1@W2\n",
    "    softmax_score = softmax(a2) \n",
    "    neg_log_softmax_score = -np.log(softmax_score+0.00000001) \n",
    "    \n",
    " \n",
    "    if i_iter%num_minibatches == 0:\n",
    "        loss = np.mean(np.diag(np.take(neg_log_softmax_score, gt_indices[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size],\\\n",
    "                                       axis=1)))\n",
    "        print(\" Epoch: {:d}, iteration: {:d}, Loss: {:6.4f} \".format(i_epoch, i_iter, loss))\n",
    "        \n",
    "        loss_list.append(loss)\n",
    "        i.append(i_iter)\n",
    "        i_epoch += 1\n",
    "        \n",
    "        plt.plot(i,loss_list)\n",
    "        \n",
    "        if i_epoch%10 == 0:\n",
    "            learning_rate /= 10.0\n",
    "            \n",
    "    \n",
    "    \n",
    "    #Backpropagation\n",
    "    gradsoft = softmax_score-y_train[batch_elem_idx*batch_size:(batch_elem_idx+1)*batch_size]\n",
    "    \n",
    "    grad_W2 = np.transpose(h1)@gradsoft\n",
    "    grad_h1 = gradsoft@np.transpose(W2)\n",
    "    grad_a1 = grad_h1*grad_relu(a1)\n",
    "    grad_W1 = x_batchinput.T@grad_a1\n",
    "    W2 -= learning_rate * grad_W2\n",
    "    W1 -= learning_rate * grad_W1\n",
    "#Plot of Loss vs Number of iterations\n",
    "plt.title(\"Cost/Loss Vs. Iterations\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"Cost/Loss\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2 = 't10k-images-idx3-ubyte'           #Importing Test images\n",
    "arr2 = idx2numpy.convert_from_file(file2)  #Converting to numpy Array\n",
    "file3 = 't10k-labels-idx1-ubyte'           #Importing test labesls\n",
    "arr3 = idx2numpy.convert_from_file(file3)  #Converting to numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = arr2\n",
    "x_test = x_test.flatten().reshape(-1,28*28) #Flatten to feed to input layer\n",
    "x_test = x_test / 255.0                     #Weâ€™ll normalize the data\n",
    "y_test = arr3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on test data is 97.95 %\n"
     ]
    }
   ],
   "source": [
    "#Validation on test data\n",
    "batch_size_test = 100\n",
    "num_minibatches = len(y_test)/batch_size_test\n",
    "test_correct = 0\n",
    "\n",
    "\n",
    "for i_iter in range(int(num_minibatches)):\n",
    "    \n",
    "    batch_elem_idx = i_iter%num_minibatches\n",
    "    x_batchinput = x_test[i_iter*batch_size_test:(i_iter+1)*batch_size_test]\n",
    "    a1 =x_batchinput@W1\n",
    "    h1 =relu(a1)\n",
    "    a2 = h1@W2\n",
    "    softmax_score = softmax(a2) \n",
    "    \n",
    "    y_batchinput = y_test[i_iter*batch_size_test:(i_iter+1)*batch_size_test]\n",
    "    \n",
    "    y_pred = np.argmax(softmax_score, axis=1)\n",
    "    num_correct_i_iter = np.sum(y_pred == y_batchinput)\n",
    "    test_correct += num_correct_i_iter\n",
    "print (\"Accuracy on test data is {:4.2f} %\".format(test_correct/len(y_test)*100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#END Note\n",
    "#Model was optimised by varying hyperparameters i.e. batch size, number of nodes in hidden layer, learning rate and number of iterations.\n",
    "#The best accuracy was found at batch size=64, nodes in hidden layer=512, learning rate=1e-2 and number of iterations=20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "2_Hidden_MLP_New.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
